# FAQ Answering with DistilBERT â€” NLP Project

This repository contains our final project notebook for building an FAQ-style question answering model using DistilBERT. The goal of the project was to combine university FAQ data with a sampled portion of the SQuAD dataset and evaluate how well a lightweight transformer model can perform retrieval-style question answering.

The notebook walks through:

- Loading and preprocessing the FAQ + SQuAD datasets  
- Tokenization and input formatting  
- Fine-tuning DistilBERT for classification  
- Tracking loss, Exact Match, and Top-1 Accuracy
